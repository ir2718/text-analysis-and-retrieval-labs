{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77230ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed8a00df369ce38f9743ed412973d72b",
     "grade": false,
     "grade_id": "cell-cbdf7d65ea58446b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "University of Zagreb\\\n",
    "Faculty of Electrical Engineering and Computing\n",
    "\n",
    "## Text Analysis and Retrieval 2021/2022\n",
    "https://www.fer.unizg.hr/predmet/apt/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee22e58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9b48444c442d59c241b49ba429238dd",
     "grade": false,
     "grade_id": "cell-5e9c1e104dec0dd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------------------------------\n",
    "\n",
    "### Semantics\n",
    "### LAB 2\n",
    "\n",
    "\n",
    "*Version: 1.0*\n",
    "\n",
    "(c) 2022 Josip Jukić, Jan Šnajder\n",
    "\n",
    "Submission deadline: **May 4, 2022, 23:59 CET** \n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333437b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6233aca5abb9b3f8b6a7a6080fb096fb",
     "grade": false,
     "grade_id": "cell-b25d76fa7c847af2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "Hello visitor, this lab assignment consists of three parts. Your task boils down to filling out the missing parts of code and evaluating the cells. These parts are indicated by the \"YOUR CODE HERE\" template.\n",
    "\n",
    "Each subtask is supplemented by several tests that you can run. Apart from that, there are additional test that will be executed after submition. If your solution is valid and it passes all of the visible tests, there shouldn't be any problems with the additional tests.\n",
    "\n",
    "**IMPORTANT: Don't change the names of the predefined methods or random seeds**, because the tests won't execute properly.\n",
    "\n",
    "You're required to do this assignment **on your own**.\n",
    "\n",
    "If you stumble upon problems, please refer to josip.jukic@fer.hr for office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336f31b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd1654b2c7c8de8e1d1cfaeeee261ec2",
     "grade": false,
     "grade_id": "cell-150c23ae802b9522",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52503faa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d5b35025abd60b2ec4d24bb43494673",
     "grade": false,
     "grade_id": "cell-95afad8333fec3bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Paraphrase identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e247b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8003466213056de71915ec4c716b5f6d",
     "grade": false,
     "grade_id": "cell-7caecd650447b599",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The goal of paraphrase identification is to determine whether a pair of sentences have the same meaning. In this assignment, we will use the [MRPC](https://paperswithcode.com/dataset/mrpc) dataset, a part of the [GLUE benchmark](https://gluebenchmark.com/).\n",
    "\n",
    "Load the data frames (train & test) and explore their structure. The column `label` indicates whether a given pair of sentences is semantically equivalent (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85def3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amrozi accused his brother , whom he called \" ...</td>\n",
       "      <td>Referring to him as only \" the witness \" , Amr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yucaipa owned Dominick 's before selling the c...</td>\n",
       "      <td>Yucaipa bought Dominick 's in 1995 for $ 693 m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10 , the ship 's owners had published ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Around 0335 GMT , Tab shares were up 19 cents ...</td>\n",
       "      <td>Tab shares jumped 20 cents , or 4.6 % , to set...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The stock rose $ 2.11 , or about 11 percent , ...</td>\n",
       "      <td>PG &amp; E Corp. shares jumped $ 1.63 or 8 percent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  Amrozi accused his brother , whom he called \" ...   \n",
       "1  Yucaipa owned Dominick 's before selling the c...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT , Tab shares were up 19 cents ...   \n",
       "4  The stock rose $ 2.11 , or about 11 percent , ...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  Referring to him as only \" the witness \" , Amr...      1  \n",
       "1  Yucaipa bought Dominick 's in 1995 for $ 693 m...      0  \n",
       "2  On June 10 , the ship 's owners had published ...      1  \n",
       "3  Tab shares jumped 20 cents , or 4.6 % , to set...      0  \n",
       "4  PG & E Corp. shares jumped $ 1.63 or 8 percent...      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load CSV files.\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb727d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "222ebb1c9eb1e6f50e52bad8b4e68a83",
     "grade": false,
     "grade_id": "cell-05a53297f6695a37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The library that will do the heavy lifting for this task is [Podium](https://takelab.fer.hr/podium/), TakeLab's data loading and preprocessing tool for NLP. We advise you to take a look at the official documenation as well as the [walkthrough](https://takelab.fer.hr/podium/walkthrough.html) examples. Additionally, go through the main primitives: [Vocab](https://takelab.fer.hr/podium/package_reference/vocab_and_fields.html#vocab), [Field](https://takelab.fer.hr/podium/package_reference/vocab_and_fields.html#field), and [Dataset](https://takelab.fer.hr/podium/package_reference/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bfcbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paramiko\\transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from podium import Vocab, Field, LabelField\n",
    "from podium.datasets import TabularDataset\n",
    "from podium.vectorizers import GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e673b2d3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fc507e3ad32586f15570905da09ec88",
     "grade": false,
     "grade_id": "cell-9c4e4d599e282ec6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (a)\n",
    "\n",
    "Construct three fields: `sentence1` (Field), `sentence2` (Field), and `label` (LabelField). Transform the sentences to lower case using the attribute `pretokenize_hooks`. Refer to the [documentation](https://takelab.fer.hr/podium/preprocessing.html#hooks) to see how this can be achieved.\n",
    "\n",
    "In order to model semantics, we will utilize [GloVe](https://nlp.stanford.edu/projects/glove/) distributional word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d31db5d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4b67c7d503b99e70e3ea563ed12c399",
     "grade": false,
     "grade_id": "cell-dff7bf4dffadbf13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\podium\\vocab.py:514: UserWarning: Vocabulary is finalized already. This should be used only if multiple fields use same vocabulary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_vocab_size = 10_000\n",
    "vocab = Vocab(max_size=max_vocab_size, min_freq=2)\n",
    "\n",
    "S1 = None # Sentence1 field\n",
    "S2 = None # Sentence2 field\n",
    "LABEL = None # Label field\n",
    "\n",
    "S1 = Field('sentence1', numericalizer=vocab, pretokenize_hooks=str.lower)\n",
    "S2 = Field('sentence2', numericalizer=vocab, pretokenize_hooks=str.lower)\n",
    "LABEL = LabelField('label')\n",
    "\n",
    "fields = [\n",
    "    S1,\n",
    "    S2,\n",
    "    LABEL,\n",
    "]\n",
    "\n",
    "train = TabularDataset.from_pandas(df_train, fields)\n",
    "test = TabularDataset.from_pandas(df_test, fields)\n",
    "train.finalize_fields()\n",
    "\n",
    "glove = GloVe()\n",
    "# Load only the vectors of vocab words.\n",
    "embeddings = glove.load_vocab(vocab)\n",
    "\n",
    "# Generate padded batch.\n",
    "train_batch = train.batch(add_padding=True)\n",
    "test_batch = test.batch(add_padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d202fbfc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23dbb38bd32d5dcac039e1affb20c4e3",
     "grade": true,
     "grade_id": "cell-d078098275346006",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert \"washington\" in vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7d133",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "498106dc5b2f653a5e0a2d8f1cebe010",
     "grade": false,
     "grade_id": "cell-6f84a2e14ea825e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Generated batch stores values for the corresponding fields, which can be accessed with the dot notation. See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88ca1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1319,  471,   33, ...,    1,    1,    1],\n",
       "        [5929, 1799, 5930, ...,    1,    1,    1],\n",
       "        [  40,   36,  669, ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [  10,   50,   34, ...,    1,    1,    1],\n",
       "        [   2, 5757,   16, ...,    1,    1,    1],\n",
       "        [   2,  916,  469, ...,    1,    1,    1]]),\n",
       " array([[2482,    5,  138, ...,    1,    1,    1],\n",
       "        [5929, 1968, 5930, ...,    1,    1,    1],\n",
       "        [  13,  184,  148, ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   7,    8,  140, ...,    1,    1,    1],\n",
       "        [   0,   57,  153, ...,    1,    1,    1],\n",
       "        [   2,  916,  469, ...,    1,    1,    1]]),\n",
       " array([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch.sentence1, train_batch.sentence2, train_batch.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82a9ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "caf466ce0fd3fdf4cda671794ee40d56",
     "grade": false,
     "grade_id": "cell-29c126a7fde72a9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (b)\n",
    "\n",
    "Implement `cosine_similarity`, which computes cosine similarities of two 2D arrays across their second axis (index = 1). Refer to the tests below to see a concrete example. [np.einsum](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html) and [np.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html) may be useful for this task. However, you are not obliged to use those methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc501e6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89b665abb2ca111c1c5cb0125d3f81df",
     "grade": false,
     "grade_id": "cell-f0747bf03a37381a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Receives two 2D numpy arrays and calculates cosine similarity across the second axis.\n",
    "    For examples, if `a` and `b` have shape (32, 10), the resulting array should have shape (32,).\n",
    "    \n",
    "    Returns:\n",
    "        1D numpy array with cosine similarities\n",
    "    \"\"\"\n",
    "    return np.einsum('ij,ij->i', a, b)/(np.linalg.norm(a, axis=1) * np.linalg.norm(b, axis=1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e7a058",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb7c554cbdc752cb7f9ea79f065403d5",
     "grade": true,
     "grade_id": "cell-6710738e2774f997",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "a = np.array(\n",
    "    [\n",
    "        [0.79674043, -0.21774995, 0.24626283, -1.92507862, -0.44471655],\n",
    "        [-0.83365243, -1.05258529, -0.69114343, 1.94794818, 0.81859483],\n",
    "        [-1.1742791, 0.39978046, -1.14265924, 1.50492221, 0.99339915],\n",
    "        [0.58896543, 0.8214453, -0.27131406, 0.45817815, -0.21055904],\n",
    "    ]\n",
    ")\n",
    "\n",
    "b = np.array(\n",
    "    [\n",
    "        [0.20286607, 0.34114231, -1.14127489, 0.11783557, -0.43729267],\n",
    "        [0.34177672, -1.66142734, 1.13159559, 0.07148497, 0.24896589],\n",
    "        [-0.10376178, 0.30639966, 0.54675361, -0.04626362, 0.1408809],\n",
    "        [-0.6056932, -1.24619744, -0.2720515, 1.26427211, 1.47021337],\n",
    "    ]\n",
    ")\n",
    "\n",
    "sol = np.array([-0.08127636, 0.1919786, -0.19251815, -0.37211115])\n",
    "\n",
    "assert np.isclose(cosine_similarity(a, b), sol).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c7a90",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed4c8c70dac9cff2987b9d00a3696cb9",
     "grade": false,
     "grade_id": "cell-59a7a22cb3eb23fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (c)\n",
    "Implement `top_n`, which retrieves the sorted indices of top `n` values in a numpy array. Refer to the test below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b0a6c3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ec8f9312ee6d068f6a60f461a3e8c7",
     "grade": false,
     "grade_id": "cell-aa7506bc0511eecf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_n(sims, n=10):\n",
    "    \"\"\"\n",
    "    Receives a numpy array `sims` and finds the indices of the top `n` highest similarities.\n",
    "    The indices are returned in the ascending order (from lowest to highest index).\n",
    "    \"\"\"\n",
    "    return np.argsort(sims)[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614bec35",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45131a63bcff88d79a43b1b0f136bf31",
     "grade": true,
     "grade_id": "cell-061d712459e09a1a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (top_n(np.array([0.1, 0.5, 0.2, 0.3, 0.9]), 2) == np.array([1, 4])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e3234",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3725ea1f2ee3d640d78a5281d72f8d0",
     "grade": false,
     "grade_id": "cell-f0bd1b3236a4dab6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (d)\n",
    "We need to somehow transform the sequences to fixed-size vectors. We will explore several simple approaches.\n",
    "\n",
    "Extract word embeddings for sentence1 and sentence2 (both for train and test), using `train_batch`, `test_batch`, and `embeddings`. Additionally, compute the mean embedding for both fields and both sets. Store them to `sentence1_train_mean`, `sentence2_train_mean`, `sentence1_test_mean`, and `sentence2_test_mean`.\n",
    "\n",
    "Once you compute the means, retrieve and print out the top 10 most similar sentence pairs from the train set using the previously implemented methods `cosine_similarity` and `top_n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04849468",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e45f81166fe57966be7ee6ee95366805",
     "grade": false,
     "grade_id": "cell-63d484fa72557c59",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99968619 0.99969057 0.99969104 0.99969878 0.99972877 0.99973616\n",
      " 0.99980307 0.99981289 0.99985794 0.99992784]\n",
      "[1748 1660 2282  368  172 2385 1903 3219 2824  506]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>An attempt last month in the Senate to keep th...</td>\n",
       "      <td>An attempt to keep the fund open for another y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>The United States and Britain are seeking back...</td>\n",
       "      <td>At the United Nations , the United States and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>No pill is ever expected to replace earplugs a...</td>\n",
       "      <td>Nobody is saying such a pill could replace ear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Moore had no immediate comment Tuesday .</td>\n",
       "      <td>Moore did not have an immediate response Tuesd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>ConAgra stock closed Monday on the New York St...</td>\n",
       "      <td>ConAgra shares closed Monday at $ 21.63 a shar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>Other , more traditional tests are also availa...</td>\n",
       "      <td>Traditional tests also are available at no cos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>South Africa has the world 's highest caseload...</td>\n",
       "      <td>With 4.7 million people infected with HIV or A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>Druce will face murder charges , Conte said .</td>\n",
       "      <td>Conte said Druce will be charged with murder .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>Justices Stephen Breyer , Sandra Day O 'Connor...</td>\n",
       "      <td>Justices Anthony Kennedy , Sandra Day O 'Conno...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>The rest said they belonged to another party o...</td>\n",
       "      <td>The rest said they had no affiliation or belon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "1748  An attempt last month in the Senate to keep th...   \n",
       "1660  The United States and Britain are seeking back...   \n",
       "2282  No pill is ever expected to replace earplugs a...   \n",
       "368            Moore had no immediate comment Tuesday .   \n",
       "172   ConAgra stock closed Monday on the New York St...   \n",
       "2385  Other , more traditional tests are also availa...   \n",
       "1903  South Africa has the world 's highest caseload...   \n",
       "3219      Druce will face murder charges , Conte said .   \n",
       "2824  Justices Stephen Breyer , Sandra Day O 'Connor...   \n",
       "506   The rest said they belonged to another party o...   \n",
       "\n",
       "                                              sentence2  label  \n",
       "1748  An attempt to keep the fund open for another y...      1  \n",
       "1660  At the United Nations , the United States and ...      1  \n",
       "2282  Nobody is saying such a pill could replace ear...      1  \n",
       "368   Moore did not have an immediate response Tuesd...      1  \n",
       "172   ConAgra shares closed Monday at $ 21.63 a shar...      1  \n",
       "2385  Traditional tests also are available at no cos...      0  \n",
       "1903  With 4.7 million people infected with HIV or A...      1  \n",
       "3219     Conte said Druce will be charged with murder .      1  \n",
       "2824  Justices Anthony Kennedy , Sandra Day O 'Conno...      1  \n",
       "506   The rest said they had no affiliation or belon...      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1_train, sentence2_train = None, None\n",
    "sentence1_test, sentence2_test = None, None\n",
    "sentence1_train_mean, sentence2_train_mean = None, None\n",
    "sentence1_test_mean, sentence2_test_mean = None, None\n",
    "    \n",
    "sentence1_train = embeddings[train_batch.sentence1]\n",
    "sentence2_train = embeddings[train_batch.sentence2]\n",
    "\n",
    "sentence1_test =  embeddings[test_batch.sentence1]\n",
    "sentence2_test =  embeddings[test_batch.sentence2]\n",
    "\n",
    "sentence1_train_mean = np.mean(sentence1_train, axis=1)\n",
    "sentence2_train_mean = np.mean(sentence2_train, axis=1)\n",
    "\n",
    "sentence1_test_mean = np.mean(sentence1_test, axis=1)\n",
    "sentence2_test_mean = np.mean(sentence2_test, axis=1)\n",
    "\n",
    "similiarities = cosine_similarity(sentence1_train_mean, sentence2_train_mean)\n",
    "top = top_n(similiarities)\n",
    "\n",
    "print(similiarities[top])\n",
    "print(top)\n",
    "df_train.iloc[top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0121510d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "394d265fbf16672028e669a8b635107e",
     "grade": true,
     "grade_id": "cell-c1f16db9cca4da7a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sentence1_train_mean.shape == (len(train), 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3125fd5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7c8809f920b20c128e5ad963ff35efa",
     "grade": false,
     "grade_id": "cell-05e631d6a5c424a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (e)\n",
    "Now use the computed means to create representations. You should make two variants: `*_mul`**multiplies the values element-wise** and `*_cat` simply **concatenates** the means from sentence1 and sentence2.\n",
    "Load the train and test labels from their corresponding batches. Make sure that the label array is 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b61c345",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10b5d34acf8980c01e4f36b53e344be7",
     "grade": false,
     "grade_id": "cell-818c0bfd3a022b26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_mul, X_test_mul = None, None\n",
    "X_train_cat, X_test_cat = None, None\n",
    "y_train, y_test = None, None\n",
    "\n",
    "\n",
    "X_train_mul = sentence1_train_mean * sentence2_train_mean\n",
    "X_test_mul = sentence1_test_mean * sentence2_test_mean\n",
    "\n",
    "X_train_cat = np.concatenate((sentence1_train_mean, sentence2_train_mean), axis=1)\n",
    "X_test_cat = np.concatenate((sentence1_test_mean, sentence2_test_mean), axis=1)\n",
    "\n",
    "y_train = train_batch.label.flatten()\n",
    "y_test = test_batch.label.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8b3dc0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a0713d978a5ee0f9ebe0a59e9c13304",
     "grade": true,
     "grade_id": "cell-bb7c231933127781",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_train_mul.shape == (len(train), 300)\n",
    "assert X_train_cat.shape == (len(train), 600)\n",
    "assert y_train.shape == (len(train),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70b551",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fd42a773e54c9ab72a528fe134fc068",
     "grade": false,
     "grade_id": "cell-68f0b46758a9f780",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (f)\n",
    "Finally, let's exploit the fruits of our labor by building a classifier that will identify paraphrases. Implement `train_model` that trains an [`sklearn`](https://scikit-learn.org/stable/) model and returns the fitted model. You may use any `sklearn` model, but you need to achieve **binary $F_1$ generalization score higher than 0.4** for both represenations (multiplied and concatenated) to pass the tests. To calculate $F_1$ with `sklearn.metrics.f1_score`, set `average=\"binary\"`. See the example bellow. For additional information, we advise you to use `classification_report`. Remember that the MRPC dataset is quite challenging and we're using a simple approach, so don't be surprised with low binary $F_1$ scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ebd8d1d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6d61f9adc576122b1252072b5889e9d",
     "grade": false,
     "grade_id": "cell-1a247f119b6b096f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.77      0.58       698\n",
      "           1       0.72      0.41      0.52      1027\n",
      "\n",
      "    accuracy                           0.56      1725\n",
      "   macro avg       0.60      0.59      0.55      1725\n",
      "weighted avg       0.62      0.56      0.55      1725\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.76      0.47       516\n",
      "           1       0.79      0.38      0.51      1209\n",
      "\n",
      "    accuracy                           0.49      1725\n",
      "   macro avg       0.56      0.57      0.49      1725\n",
      "weighted avg       0.65      0.49      0.50      1725\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Fit and return the fitted sklearn model.\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(C=0.5, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "model = train_model(X_train_mul, y_train)\n",
    "y_pred = model.predict(X_test_mul)\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "model = train_model(X_train_cat, y_train)\n",
    "y_pred = model.predict(X_test_cat)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66c94d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb0739006c3e674b79c4928d8b0a8817",
     "grade": true,
     "grade_id": "cell-adfee54218548429",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8390e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c8bc51dd6134adb177418358da87694",
     "grade": true,
     "grade_id": "cell-440e012cfbed3809",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
