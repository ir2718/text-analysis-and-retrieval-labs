{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77230ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed8a00df369ce38f9743ed412973d72b",
     "grade": false,
     "grade_id": "cell-cbdf7d65ea58446b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "University of Zagreb\\\n",
    "Faculty of Electrical Engineering and Computing\n",
    "\n",
    "## Text Analysis and Retrieval 2021/2022\n",
    "https://www.fer.unizg.hr/predmet/apt/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee22e58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0129f6baa6ea4e128ede5f41d446ec67",
     "grade": false,
     "grade_id": "cell-5e9c1e104dec0dd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------------------------------\n",
    "\n",
    "### Basics of NLP\n",
    "\n",
    "*Version: 1.1*\n",
    "\n",
    "(c) 2022 Josip Jukić, Jan Šnajder\n",
    "\n",
    "Submission deadline: **April 6, 2022, 23:59 CET** \n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333437b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dec4757a699e04f5ca4b7db9a25f481",
     "grade": false,
     "grade_id": "cell-b25d76fa7c847af2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "Hello visitor, this lab assignment consists of three parts. Your task boils down to filling out the missing parts of code and evaluating the cells. These parts are indicated by the \"YOUR CODE HERE\" template.\n",
    "\n",
    "Each subtask is supplemented by several tests that you can run. Apart from that, there are additional test that will be executed after submition. If your solution is valid and it passes all of the visible tests, there shouldn't be any problems with the additional tests.\n",
    "\n",
    "**IMPORTANT: Don't change the names of the predefined methods or random seeds**, because the tests won't be executed properly.\n",
    "\n",
    "You're required to do this assignment **on your own**.\n",
    "\n",
    "If you stumble upon problems, please refer to josip.jukic@fer.hr for office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336f31b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd1654b2c7c8de8e1d1cfaeeee261ec2",
     "grade": false,
     "grade_id": "cell-150c23ae802b9522",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52503faa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0398d566c69a62089f0eb60546d6340d",
     "grade": false,
     "grade_id": "cell-95afad8333fec3bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "third-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d3b8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b155864b06eca3cc7daa9d3c05433e43",
     "grade": false,
     "grade_id": "cell-6eb6dc1bc414cf1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will use [spaCy](https://spacy.io/) exetensively in this assigment. You are advised to study the main aspects of this tool. You can go through the basics [here](https://spacy.io/usage/spacy-101). We recommend that you go through the procedures that we covered in the lectures: tokenization, lemmatization, part-of-speech (POS) tagging, and named entity recognition (NER).\n",
    "\n",
    "Furthermore, we will rely on [NumPy](https://numpy.org/) and [pandas](https://pandas.pydata.org/) libraries. If you are not familiar with those libraries, we advise you to go through [this tutorial](https://www.hackerearth.com/practice/machine-learning/data-manipulation-visualisation-r-python/tutorial-data-manipulation-numpy-pandas-python/tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49891d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d800562",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18574758fbae85b229fb5ad20ca9cdda",
     "grade": false,
     "grade_id": "cell-16202be1385f6781",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (a)\n",
    "Process the example below with spaCy. Tokenize the document and gather the tokens in a list. Finally, print the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d34e4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76f9573e9524d0566357ec211312ce57",
     "grade": false,
     "grade_id": "cell-8fa80d1ece04d737",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex1_a1 = (\n",
    "    \"A wizard is never late, Frodo Baggins. \"\n",
    "    \"Nor is he early; he arrives precisely when he means to.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8bfdd25",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eece1ba6d97bcb94ee0a4e5ae7499ac0",
     "grade": false,
     "grade_id": "cell-10252e22a675688e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A, wizard, is, never, late, ,, Frodo, Baggins, ., Nor, is, he, early, ;, he, arrives, precisely, when, he, means, to, .]\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return [token for token in nlp(text)]\n",
    "\n",
    "tokens = tokenizer(ex1_a1)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a8590",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbc65ec903d48d3665d4227c2343f2bc",
     "grade": false,
     "grade_id": "cell-bb0718d5e7f50e40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (b)\n",
    "Implement `sentencizer` using [spaCy](https://spacy.io/usage/linguistic-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8da2f50",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "640f18a880a339d3a99335a3a8164771",
     "grade": false,
     "grade_id": "cell-f24e1081f2af60b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sentencizer(text):\n",
    "    \"\"\"\n",
    "    Receives a string as an input,\n",
    "    splits the document to sentences and gathers them in a list.\n",
    "    \"\"\"\n",
    "    return [sentence.text for sentence in nlp(text).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39e0309",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7998a7e3d2e527b89800c50bdca72ba7",
     "grade": true,
     "grade_id": "cell-cda5936073984160",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sentencizer(\"Sentence no. 1. Sentence no. 2.\") == [\n",
    "    \"Sentence no. 1.\",\n",
    "    \"Sentence no. 2.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab61006",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dada93ac32be275cfea235c17f9ba0f4",
     "grade": false,
     "grade_id": "cell-a39ece84bbd22997",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (c)\n",
    "\n",
    "Implement `lemmatizer` using [spaCy](https://spacy.io/usage/linguistic-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462c67dd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e0bc45a957906ca13e967ab5e083fbc",
     "grade": false,
     "grade_id": "cell-759698a86a73114f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    \"\"\"\n",
    "    Receives a string as an input and lemmatizes it.\n",
    "    The lemmas are returned in a list.\n",
    "    \"\"\"\n",
    "    return [token.lemma_ for token in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60cad45e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28b18c2fc2b5c5c6020c81abcd5f7f26",
     "grade": true,
     "grade_id": "cell-1381a0323dde41cc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert lemmatizer(ex1_a1) == [\n",
    "    \"a\",\n",
    "    \"wizard\",\n",
    "    \"be\",\n",
    "    \"never\",\n",
    "    \"late\",\n",
    "    \",\",\n",
    "    \"Frodo\",\n",
    "    \"Baggins\",\n",
    "    \".\",\n",
    "    \"nor\",\n",
    "    \"be\",\n",
    "    \"he\",\n",
    "    \"early\",\n",
    "    \";\",\n",
    "    \"he\",\n",
    "    \"arrive\",\n",
    "    \"precisely\",\n",
    "    \"when\",\n",
    "    \"he\",\n",
    "    \"mean\",\n",
    "    \"to\",\n",
    "    \".\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ccb113",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "300d915802e7c3337f5d6fcd3ede3ed3",
     "grade": false,
     "grade_id": "cell-a20b39684be6b375",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (d)\n",
    "\n",
    "Implement the `ngrams` methods. You might find the [`tee`](https://www.geeksforgeeks.org/python-itertools-tee/) method from the `itertools` package useful, but you're not obliged to use it. The method should return a generator. Plase refer to the [link](https://wiki.python.org/moin/Generators) if you aren't familiar with Python generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06186b52",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cc9b2358491234483fce15870678054",
     "grade": false,
     "grade_id": "cell-66b11d5510c3d6ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "\n",
    "\n",
    "def ngrams(sequence, n, **kwargs):\n",
    "    \"\"\"\n",
    "    Receives a list of tokens and generates n-grams.\n",
    "    \"\"\"\n",
    "    start = 0\n",
    "    for i in range(len(sequence) - n + 1):\n",
    "        yield tuple(sequence[start : start+n])\n",
    "        start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a72da564",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0b5586930150617ae69345587517487",
     "grade": true,
     "grade_id": "cell-01b516b6b34b5d58",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert list(ngrams(lemmatizer(ex1_a1), 2)) == [\n",
    "    (\"a\", \"wizard\"),\n",
    "    (\"wizard\", \"be\"),\n",
    "    (\"be\", \"never\"),\n",
    "    (\"never\", \"late\"),\n",
    "    (\"late\", \",\"),\n",
    "    (\",\", \"Frodo\"),\n",
    "    (\"Frodo\", \"Baggins\"),\n",
    "    (\"Baggins\", \".\"),\n",
    "    (\".\", \"nor\"),\n",
    "    (\"nor\", \"be\"),\n",
    "    (\"be\", \"he\"),\n",
    "    (\"he\", \"early\"),\n",
    "    (\"early\", \";\"),\n",
    "    (\";\", \"he\"),\n",
    "    (\"he\", \"arrive\"),\n",
    "    (\"arrive\", \"precisely\"),\n",
    "    (\"precisely\", \"when\"),\n",
    "    (\"when\", \"he\"),\n",
    "    (\"he\", \"mean\"),\n",
    "    (\"mean\", \"to\"),\n",
    "    (\"to\", \".\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0feaf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "805632bc6f160ec920cb46d8ac316635",
     "grade": false,
     "grade_id": "cell-adf3d7b2e18c3c03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. News classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ebb3c",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "Load the prepared BBC news data to a `pandas` dataframe named `df_bbc`. Explore the dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93bc621a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db8a261fbf823db01013aaade4756761",
     "grade": false,
     "grade_id": "cell-46a1f24f0267c57e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New 'yob' targets to be unveiled\\n \\n Fifty ne...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newcastle line up Babayaro\\n \\n Newcastle mana...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe backs digital TV lifestyle\\n \\n How peo...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fears raised over ballet future\\n \\n Fewer chi...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barkley fit for match in Ireland\\n \\n England ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Wales 'must learn health lessons'\\n \\n The new...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Clarke to press on with ID cards\\n \\n New Home...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Artists' secret postcards on sale\\n \\n Postcar...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Lopez misses UK charity premiere\\n \\n Jennifer...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>February poll claim 'speculation'\\n \\n Reports...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  news           type\n",
       "0    New 'yob' targets to be unveiled\\n \\n Fifty ne...       politics\n",
       "1    Newcastle line up Babayaro\\n \\n Newcastle mana...          sport\n",
       "2    Europe backs digital TV lifestyle\\n \\n How peo...           tech\n",
       "3    Fears raised over ballet future\\n \\n Fewer chi...  entertainment\n",
       "4    Barkley fit for match in Ireland\\n \\n England ...          sport\n",
       "..                                                 ...            ...\n",
       "195  Wales 'must learn health lessons'\\n \\n The new...       politics\n",
       "196  Clarke to press on with ID cards\\n \\n New Home...       politics\n",
       "197  Artists' secret postcards on sale\\n \\n Postcar...  entertainment\n",
       "198  Lopez misses UK charity premiere\\n \\n Jennifer...  entertainment\n",
       "199  February poll claim 'speculation'\\n \\n Reports...       politics\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_bbc = pd.read_csv('bbc.csv')\n",
    "\n",
    "display(df_bbc)\n",
    "print(df_bbc[['type']].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a03e9",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "To make the classification task a bit more challenging, we want to remove the news title from the text.\\\n",
    "Additionally, we will replace all whitespaces with single spaces. Implement title removal and whitespace replacement in `clean_text`.\\\n",
    "E.g., \"This \\n is  \\t an &nbsp;&nbsp;&nbsp;&nbsp; example. \" -> \"This is an example.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a13f8b4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64739bab014639562d3c2be4139a6ada",
     "grade": false,
     "grade_id": "cell-51a7b044e7fb5900",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes news title and replaces all whitespaces with single spaces.\n",
    "    Returns preprocessed text.\n",
    "    \"\"\"\n",
    "    text_wo_title = ''.join(text.split('\\n')[1:])\n",
    "    return ' '.join(text_wo_title.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d7cc6d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f669133bd4f9965634a4003e0fa4fbe2",
     "grade": true,
     "grade_id": "cell-fce2e38e985bdf90",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (\n",
    "    clean_text(\"Breaking news\\nClever Hans \\t learns  to integrate.\")\n",
    "    == \"Clever Hans learns to integrate.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04359889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbc[\"text\"] = df_bbc.news.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dde023",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "(1) Implement an abstract pipeline in `preprocess_pipe`. The method receieves a sequence of texts and a pipe function, which is used to preprocess documents in combination with the spaCy model `nlp` that we loaded at the beggining. We recommend you to use [`pipe`](https://spacy.io/usage/processing-pipelines).\\\n",
    "(2) Implement `lemmatize_pipe` that collects lemmas and returns a list of n-grams ranging from `ngram_min` to `ngram_max`. Additonally, **truncate** the documents to `max_len` tokens and **remove the stop words**. Refer to the tests below to see how this method should behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a8d5c10",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "871d62e1e2fecb7c68afcc50a4a1c15d",
     "grade": false,
     "grade_id": "cell-d767fae648cfcd8c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_pipe(doc, max_len, ngram_min, ngram_max):\n",
    "    \"\"\"\n",
    "    Removes stopword, truncates the document to `max_len` tokens,\n",
    "    and returns lemma n-grams in range [`ngram_min`, `ngram_max`].\n",
    "    \"\"\"\n",
    "    docs_stopw = [token for token in doc if not token.is_stop][:max_len]\n",
    "    docs_stopw_lower = [token.lemma_.lower() if token.pos_ != 'PROPN' else token.lemma_ for token in docs_stopw]\n",
    "    l = []\n",
    "    for n in (ngram_min, ngram_max):\n",
    "        tmp = list(ngrams(docs_stopw_lower, n))\n",
    "        l.extend(tmp)\n",
    "    return l\n",
    "        \n",
    "def preprocess_pipe(texts, pipe_fn):\n",
    "    l = []\n",
    "    for doc in nlp.pipe(texts):\n",
    "        l.append(pipe_fn(doc))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fa0dc4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eaaf424e75df3ace41f83b75cca082e4",
     "grade": true,
     "grade_id": "cell-17c77fd435574993",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "pipe_fn = partial(lemmatize_pipe, max_len=100, ngram_min=1, ngram_max=2)\n",
    "\n",
    "ex2_c1 = [\"Text no. 1\", \"Text no. 2\"]\n",
    "sol2_c1 = [\n",
    "    [(\"text\",), (\".\",), (\"1\",), (\"text\", \".\"), (\".\", \"1\")],\n",
    "    [(\"text\",), (\".\",), (\"2\",), (\"text\", \".\"), (\".\", \"2\")],\n",
    "]\n",
    "\n",
    "assert preprocess_pipe(ex2_c1, pipe_fn) == sol2_c1\n",
    "\n",
    "ex2_c2 = [\n",
    "    \"It’s a dangerous business, Frodo, going out your door.\",\n",
    "    \"You step onto the road, and if you don’t keep your feet, there’s no knowing where you might be swept off to.\",\n",
    "]\n",
    "sol2_c2 = [\n",
    "    [\n",
    "        (\"dangerous\",),\n",
    "        (\"business\",),\n",
    "        (\",\",),\n",
    "        (\"Frodo\",),\n",
    "        (\",\",),\n",
    "        (\"go\",),\n",
    "        (\"door\",),\n",
    "        (\".\",),\n",
    "        (\"dangerous\", \"business\"),\n",
    "        (\"business\", \",\"),\n",
    "        (\",\", \"Frodo\"),\n",
    "        (\"Frodo\", \",\"),\n",
    "        (\",\", \"go\"),\n",
    "        (\"go\", \"door\"),\n",
    "        (\"door\", \".\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"step\",),\n",
    "        (\"road\",),\n",
    "        (\",\",),\n",
    "        (\"foot\",),\n",
    "        (\",\",),\n",
    "        (\"know\",),\n",
    "        (\"sweep\",),\n",
    "        (\".\",),\n",
    "        (\"step\", \"road\"),\n",
    "        (\"road\", \",\"),\n",
    "        (\",\", \"foot\"),\n",
    "        (\"foot\", \",\"),\n",
    "        (\",\", \"know\"),\n",
    "        (\"know\", \"sweep\"),\n",
    "        (\"sweep\", \".\"),\n",
    "    ],\n",
    "]\n",
    "\n",
    "assert preprocess_pipe(ex2_c2, pipe_fn) == sol2_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e927475",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95eaa9fbfa6690d857b87f093ce96ab9",
     "grade": false,
     "grade_id": "cell-4f1b437a60d59263",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pipe_fn = partial(lemmatize_pipe, max_len=100, ngram_min=1, ngram_max=2)\n",
    "\n",
    "df_bbc[\"lemmas\"] = preprocess_pipe(df_bbc.text, pipe_fn)\n",
    "df_bbc_train, df_bbc_test = train_test_split(\n",
    "    df_bbc[[\"lemmas\", \"type\"]], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41262657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Load vectorizers\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16506e26",
   "metadata": {},
   "source": [
    "#### (d)\n",
    "Implement `train_lr`. Run `test_performance` with count and TF-IDF vectorizer. Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02d032e1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba851ee17994c47b71e16eb24c255e91",
     "grade": false,
     "grade_id": "cell-3ffaa74fc8341360",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "\n",
    "def train_lr(df_train, vectorizer, lr_kwargs={\"max_iter\": 1000, \"solver\": \"lbfgs\"}):\n",
    "    \"\"\"\n",
    "    Receives the train set `df_train` as pd.DataFrame and extracts lemma n-grams\n",
    "    with their correspoding labels (news type).\n",
    "    The text is vectorized and used to train a logistic regression with\n",
    "    training arguments passed as `lr_kwargs`.\n",
    "    Returns the fitted model.\n",
    "    \"\"\"\n",
    "    X = vectorizer.fit_transform(df_train['lemmas'])\n",
    "    y = df_train['type']\n",
    "    \n",
    "    model = LR(max_iter=lr_kwargs['max_iter'], solver=lr_kwargs['solver'])\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaa13b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def test_performance(model, df_test, vectorizer):\n",
    "    X_test, y_test = df_test.lemmas, df_test.type\n",
    "    X_vec = vectorizer.transform(X_test)\n",
    "    y_pred = model.predict(X_vec)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fffebe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85d7002a20bc26808eb96c9c519748cb",
     "grade": true,
     "grade_id": "cell-b4268c290c91d4c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1a933bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.92      1.00      0.96        11\n",
      "entertainment       1.00      0.83      0.91         6\n",
      "     politics       1.00      1.00      1.00         8\n",
      "        sport       0.92      1.00      0.96        12\n",
      "         tech       1.00      0.67      0.80         3\n",
      "\n",
      "     accuracy                           0.95        40\n",
      "    macro avg       0.97      0.90      0.93        40\n",
      " weighted avg       0.95      0.95      0.95        40\n",
      "\n",
      "f1 = 0.925\n"
     ]
    }
   ],
   "source": [
    "## Count vectorizer scenario\n",
    "lr = train_lr(df_bbc_train, count_vectorizer)\n",
    "f1 = test_performance(lr, df_bbc_test, count_vectorizer)\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ef13b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.85      1.00      0.92        11\n",
      "entertainment       1.00      0.67      0.80         6\n",
      "     politics       1.00      1.00      1.00         8\n",
      "        sport       0.92      1.00      0.96        12\n",
      "         tech       1.00      0.67      0.80         3\n",
      "\n",
      "     accuracy                           0.93        40\n",
      "    macro avg       0.95      0.87      0.90        40\n",
      " weighted avg       0.93      0.93      0.92        40\n",
      "\n",
      "f1 = 0.895\n"
     ]
    }
   ],
   "source": [
    "## TF-IDF vectorizer scenario\n",
    "lr = train_lr(df_bbc_train, tfidf_vectorizer)\n",
    "f1 = test_performance(lr, df_bbc_test, tfidf_vectorizer)\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64facf03",
   "metadata": {},
   "source": [
    "### 3. Named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ff418",
   "metadata": {},
   "source": [
    "Named entity recognition (NER) is a NLP that seeks to classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, quantities, monetary values, percentages, etc. Refer to [Jurafsky \\& Martin, Speech and Language Processing, Chapter 17](https://web.stanford.edu/~jurafsky/slp3/17.pdf) for additional information.\n",
    "\n",
    "In this task, we will try out two approaches:\n",
    "1. **classification**, where we classify named entities for each word in a document,\n",
    "2. and **sequence labeling**, a more natural way to solve NER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d891e",
   "metadata": {},
   "source": [
    "First, let's see spaCy's visualization tool `displacy` in action. We will take the first document from our data frame and render named entities with spaCy's default NER model. Although there are some minor innacuracies, spaCy's NER model generally performs very well (~90% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae0ebf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">New 'yob' targets to be unveiled</br> </br> \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fifty\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " new areas getting special help to fight anti-social behaviour in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    England\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wales\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " will be named on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</br> </br> \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ten\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " areas have already had access to special prosecutors and local experts and the government is now expanding the crackdown to more towns and cities. Details of how many anti-social behaviour orders (\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asbos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ") were used in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " are also being published. Labour sees nuisance behaviour as a key election issue but critics claim the record is at best patchy. \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    A year ago\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", ministers launched their anti-social behaviour plan and \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "'s figures offer a progress check. They will say that in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the past year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than 2,600\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " anti-social behaviour orders were issued by the courts - more than double the total used in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the previous four years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</br> </br> Police have also closed \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    150\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " crack houses and issued \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than 400\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " dispersal orders, breaking up groups of youths in public places. The \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    50\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " new pilot areas to get special attention will also receive extra government funding. Exeter and Cardiff are among cities who have voiced interest in being involved.</br> </br> Prime Minister \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tony Blair\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is also expected to announce new measures to strengthen the use of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asbos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and fixed penalty notices. There are still concerns that some areas of the country are not using the powers properly.</br> </br> He is expected to say that the new figures were heartening but he would not rest until similar action was taken in all areas of the country where it was needed. &quot;We have not defeated this problem by any means, but shown together what can be done,&quot; he will say. Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Blair\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    this week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " defended the shake-up of the licensing laws, saying it was right to focus on troublemakers rather than treating everybody as a potential drunken nuisance.</br> </br> Ministers also boast of record police numbers and are speeding up plans to put in place \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    25,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " community support officers (CSOs). But researchers from \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Leeds University\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " warned that CSOs could undermine traditional bonds between police officers and communities. More work needed to be done on clarifying the role of different agencies and how they linked together before CSOs, they argued in a the study. Critics of the government say it has announced \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than 20\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " initiatives to tackle nuisance behaviour when the real focus should be on good policing. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Home Office\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " Minister \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hazel Blears\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " also revealed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    this week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " that &quot;\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    about a third\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "&quot; of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asbos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " were breached - with some people jailed and others not.</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "\n",
    "doc = nlp(df_bbc.news.iloc[0])\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d6da4",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "We want to use spaCy's deafult model to produce silver standard NER labels for our BBC news dataset. First step is to implement `entity_pipe`, a method that extracts POS tags and NER labels, which we will pass as an argument to `preprocess_pipe`. `entity_pipe` receives a spaCy document, extracts triplets in the form of (token, POS tag, named entity label), and returns the list of collected triplets. Refer to [spaCy's documention for NER](https://spacy.io/usage/linguistic-features#named-entities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bf8c6bd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "467a7938cfe111e1fc1a8e1c1f2d5f2b",
     "grade": false,
     "grade_id": "cell-fd433993b28d314c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entity_pipe(doc):\n",
    "    tmp = []\n",
    "    for token in doc:\n",
    "        elem = (token.text, token.tag_, token.ent_iob_ if token.ent_iob_ == 'O' else token.ent_iob_ + '-' + token.ent_type_)\n",
    "        tmp.append(elem)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76b328ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11ede27ac8ab161d7a4d486237198c50",
     "grade": true,
     "grade_id": "cell-d6d93f8d56b0d8e9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "ex3_a1 = [\n",
    "    \"One does not simply walk into Mordor.\",\n",
    "    \"What about second breakfast?\",\n",
    "]\n",
    "sol3_a1 = [\n",
    "    [\n",
    "        (\"One\", \"PRP\", \"O\"),\n",
    "        (\"does\", \"VBZ\", \"O\"),\n",
    "        (\"not\", \"RB\", \"O\"),\n",
    "        (\"simply\", \"RB\", \"O\"),\n",
    "        (\"walk\", \"VB\", \"O\"),\n",
    "        (\"into\", \"IN\", \"O\"),\n",
    "        (\"Mordor\", \"NNP\", \"B-ORG\"),\n",
    "        (\".\", \".\", \"O\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"What\", \"WP\", \"O\"),\n",
    "        (\"about\", \"IN\", \"O\"),\n",
    "        (\"second\", \"JJ\", \"B-ORDINAL\"),\n",
    "        (\"breakfast\", \"NN\", \"O\"),\n",
    "        (\"?\", \".\", \"O\"),\n",
    "    ],\n",
    "]\n",
    "assert preprocess_pipe(ex3_a1, entity_pipe) == sol3_a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c69b04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30e959aa7eca996b98a9b41d3b7c8ed8",
     "grade": false,
     "grade_id": "cell-3a37ef269efc526a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will only the first 50 documents to reduce the computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b73af685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>POS</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fifty</td>\n",
       "      <td>CD</td>\n",
       "      <td>B-CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>areas</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>getting</td>\n",
       "      <td>VBG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>special</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  POS         tag\n",
       "0    Fifty   CD  B-CARDINAL\n",
       "1      new   JJ           O\n",
       "2    areas  NNS           O\n",
       "3  getting  VBG           O\n",
       "4  special   JJ           O"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbc_trunc = df_bbc[:50].copy()\n",
    "\n",
    "df_bbc_trunc[\"tags\"] = preprocess_pipe(df_bbc_trunc[\"text\"], entity_pipe)\n",
    "data = sum(df_bbc_trunc[\"tags\"], [])\n",
    "tokens, pos, tags = zip(*data)\n",
    "df_iob = pd.DataFrame({\"token\": tokens, \"POS\": pos, \"tag\": tags})\n",
    "df_iob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e0688",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bde96fc0c7fde0b4f522a516ffe4f6f",
     "grade": false,
     "grade_id": "cell-19cd1a79d82d17df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (b)\n",
    "Vectorize the data in `df_iob` with [`DictVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html). You can transform the datafframe to a dictionary with [`to_dict`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html). The structure of the dictionary should look like so: [{column -> value}, … , {column -> value}]. Refer to the linked documentation to see how to utilize the `orient` argument.\n",
    "After vectorization, split the data using [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with `test_size=0.5` and `shuffle=False` to preserve the sentence structure. We are trying to classify named entites, so you can simply use the `tag` column from `df_iob` to extract labels. You can keep them in the string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "parallel-steal",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc6458a88505e29243276ccec489156a",
     "grade": false,
     "grade_id": "cell-771cc8409e2ed46c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "d = df_iob[['token', 'POS']].to_dict(orient='records')\n",
    "vectorizer = DictVectorizer()\n",
    "X = vectorizer.fit_transform(d)\n",
    "y = df_iob['tag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4cbc36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d24ae3f1d8bd30fa44c91e3d8ab1e1d4",
     "grade": true,
     "grade_id": "cell-08e13487d4b2350c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e4cd71a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c03e28fc594e7eb252c21f09359f647",
     "grade": false,
     "grade_id": "cell-c98f6159909f5178",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can train your classifier now. For this purpose, let's choose Multinomial Naïve Bayes (MNB). Since MNB can learn incrementally, notice that we train our model with [`partial_fit`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.partial_fit) to reduce the computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2755858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ivan\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   B-CARDINAL       0.49      0.36      0.42        83\n",
      "       B-DATE       0.51      0.18      0.26       157\n",
      "      B-EVENT       0.00      0.00      0.00         4\n",
      "        B-FAC       0.00      0.00      0.00         2\n",
      "        B-GPE       0.87      0.42      0.57       205\n",
      "   B-LANGUAGE       0.00      0.00      0.00         0\n",
      "        B-LAW       0.00      0.00      0.00         1\n",
      "        B-LOC       0.00      0.00      0.00        25\n",
      "      B-MONEY       0.00      0.00      0.00        44\n",
      "       B-NORP       0.00      0.00      0.00        56\n",
      "    B-ORDINAL       0.00      0.00      0.00        14\n",
      "        B-ORG       0.61      0.14      0.23       217\n",
      "    B-PERCENT       0.00      0.00      0.00        33\n",
      "     B-PERSON       0.86      0.13      0.23       189\n",
      "    B-PRODUCT       0.00      0.00      0.00         4\n",
      "   B-QUANTITY       0.00      0.00      0.00         4\n",
      "       B-TIME       0.00      0.00      0.00         8\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         6\n",
      "   I-CARDINAL       0.56      0.18      0.27        28\n",
      "       I-DATE       0.00      0.00      0.00       148\n",
      "      I-EVENT       0.00      0.00      0.00         9\n",
      "        I-FAC       0.00      0.00      0.00         2\n",
      "        I-GPE       0.00      0.00      0.00        34\n",
      "        I-LAW       0.00      0.00      0.00         2\n",
      "        I-LOC       0.00      0.00      0.00         7\n",
      "      I-MONEY       0.00      0.00      0.00        23\n",
      "       I-NORP       0.00      0.00      0.00         5\n",
      "        I-ORG       1.00      0.04      0.08       170\n",
      "    I-PERCENT       0.00      0.00      0.00        49\n",
      "     I-PERSON       0.50      0.06      0.10       139\n",
      "    I-PRODUCT       0.00      0.00      0.00         2\n",
      "   I-QUANTITY       0.00      0.00      0.00        10\n",
      "       I-TIME       0.00      0.00      0.00         5\n",
      "I-WORK_OF_ART       0.00      0.00      0.00        10\n",
      "            O       0.87      1.00      0.93      9379\n",
      "\n",
      "    micro avg       0.87      0.87      0.87     11074\n",
      "    macro avg       0.18      0.07      0.09     11074\n",
      " weighted avg       0.81      0.87      0.82     11074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "classes = np.unique(df_iob.tag.values).tolist()\n",
    "nb = MultinomialNB()\n",
    "nb.partial_fit(X_train, y_train, classes)\n",
    "\n",
    "print(classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d70f2",
   "metadata": {},
   "source": [
    "For non-sparse classes, the $F_1$ score should be close to $1$. The possible explanation is that spaCy's default NER model is rule-based, which makes it easy to learn. Remeber that we used spaCy to produce silver labels. To check how the classifier performs on human-annotated data, let's explore the next dataset \"ner.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f8946f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner = pd.read_csv(\"ner.csv\", encoding=\"ISO-8859-1\")\n",
    "# Fill NaNs with preceding values (for the \"Sentence #\" column).\n",
    "df_ner.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfde73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93f9dd003fc8a5d3a8d9026eae8bc509",
     "grade": false,
     "grade_id": "cell-48b614c32d72b784",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Repeat the same procedure as in **(b)** with [`DictVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) on `df_clf`. Use [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with `test_size=0.5` and `shuffle=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "134e69c4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "429e2dde8d5aa0c8ea218e365a7328f5",
     "grade": false,
     "grade_id": "cell-d4fbdfec3e6fea05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df_clf = df_ner[[\"Word\", \"POS\", \"Tag\"]]\n",
    "\n",
    "d = df_clf[['Word', 'POS']].to_dict(orient='records')\n",
    "vectorizer = DictVectorizer()\n",
    "X = vectorizer.fit_transform(d)\n",
    "y = df_clf['Tag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)\n",
    "\n",
    "classes = np.unique(df_clf.Tag.values).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8d11f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba7146f0e740162ab6e6b5b57716c882",
     "grade": true,
     "grade_id": "cell-8a44880e7fc3e9e7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de52b4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020728d",
   "metadata": {},
   "source": [
    "Let's drop the `O` tag, since it is the most frequent tag and it is hard to interpret the performance quality when it is included. This will give us a more realistic `F_1` score. If you wish, you can compare the results by setting `labels=classes` instead of `labels=new_classes`. If your classifier performs terribly, that is expected, so don't worry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ec86735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        27\n",
      "       B-eve       0.00      0.00      0.00        14\n",
      "       B-geo       0.41      0.94      0.57      1813\n",
      "       B-gpe       0.96      0.68      0.80       772\n",
      "       B-nat       0.00      0.00      0.00        12\n",
      "       B-org       0.65      0.33      0.44       917\n",
      "       B-per       0.81      0.44      0.57       879\n",
      "       B-tim       0.87      0.63      0.73       943\n",
      "       I-art       0.00      0.00      0.00        16\n",
      "       I-eve       0.00      0.00      0.00        14\n",
      "       I-geo       0.90      0.23      0.37       387\n",
      "       I-gpe       0.00      0.00      0.00        20\n",
      "       I-nat       0.00      0.00      0.00         2\n",
      "       I-org       0.72      0.28      0.40       781\n",
      "       I-per       0.64      0.31      0.41       915\n",
      "       I-tim       0.00      0.00      0.00       310\n",
      "\n",
      "   micro avg       0.57      0.52      0.55      7822\n",
      "   macro avg       0.37      0.24      0.27      7822\n",
      "weighted avg       0.65      0.52      0.52      7822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "print(\n",
    "    classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels=new_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c05cc",
   "metadata": {},
   "source": [
    "Let's try to improve the performance with the sequence labeling approach. Specifically, we're going to use CRF. First, we have to prepare the sentence-level dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88e6739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "\n",
    "sentences = df_ner.groupby(\"Sentence #\").Word.agg(lambda s: \" \".join(s)).values.tolist()\n",
    "processed = preprocess_pipe(sentences, entity_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452f6a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59dbded5cc9fd965a775314629ff6986",
     "grade": false,
     "grade_id": "cell-b81b065411cd357a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (c)\n",
    "Implement missing features in `token2features`:\n",
    "- -1:token.lower() = preceding token in lowercase\n",
    "- -1:token.istitle() = is the preceding token a title\n",
    "- -1:token.isupper() = is the preceding token a digit\n",
    "- -1:postag = POS tag of the preceding token\n",
    "\n",
    "Analogously, add the same features for succeeding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "197cedf6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1f924372b07f791f8a0ff32da3dc8aa",
     "grade": false,
     "grade_id": "cell-4f8ca4c7a8c34404",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def token2features(sent, i):\n",
    "    token = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        \"bias\": 1.0,\n",
    "        \"token.lower()\": token.lower(),\n",
    "        \"token[-3:]\": token[-3:],\n",
    "        \"token[-2:]\": token[-2:],\n",
    "        \"token.isupper()\": token.isupper(),\n",
    "        \"token.istitle()\": token.istitle(),\n",
    "        \"token.isdigit()\": token.isdigit(),\n",
    "        \"postag\": postag,\n",
    "        \"postag[:2]\": postag[:2]\n",
    "    }\n",
    "    if i > 0:\n",
    "        features.update(\n",
    "            {\n",
    "                \"-1:token.lower()\": sent[i-1][0].lower(),\n",
    "                \"-1:token.istitle()\": sent[i-1][0].istitle(),\n",
    "                \"-1:token.isupper()\": sent[i-1][0].isupper(),\n",
    "                \"-1:postag\": sent[i-1][1],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        features[\"BOS\"] = True\n",
    "        \n",
    "    if i < len(sent) - 1:\n",
    "        features.update(\n",
    "            {\n",
    "                \"+1:token.lower()\": sent[i+1][0].lower(),\n",
    "                \"+1:token.istitle()\": sent[i+1][0].istitle(),\n",
    "                \"+1:token.isupper()\": sent[i+1][0].isupper(),\n",
    "                \"+1:postag\": sent[i+1][1],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        features[\"EOS\"] = True\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [token2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for _, _, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, _, _ in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fa25a9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae60f5765168b4432b3a0e8fe1b58eee",
     "grade": true,
     "grade_id": "cell-ce2404350ff8e421",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex3_b1 = [\n",
    "    (\"Thousands\", \"NNS\", \"B-CARDINAL\"),\n",
    "    (\"of\", \"IN\", \"O\"),\n",
    "    (\"demonstrators\", \"NNS\", \"O\"),\n",
    "    (\"have\", \"VBP\", \"O\"),\n",
    "    (\"marched\", \"VBN\", \"O\"),\n",
    "    (\"through\", \"IN\", \"O\"),\n",
    "    (\"London\", \"NNP\", \"B-GPE\"),\n",
    "    (\"to\", \"TO\", \"O\"),\n",
    "    (\"protest\", \"VB\", \"O\"),\n",
    "    (\"the\", \"DT\", \"O\"),\n",
    "    (\"war\", \"NN\", \"O\"),\n",
    "    (\"in\", \"IN\", \"O\"),\n",
    "    (\"Iraq\", \"NNP\", \"B-GPE\"),\n",
    "    (\"and\", \"CC\", \"O\"),\n",
    "    (\"demand\", \"VB\", \"O\"),\n",
    "    (\"the\", \"DT\", \"O\"),\n",
    "    (\"withdrawal\", \"NN\", \"O\"),\n",
    "    (\"of\", \"IN\", \"O\"),\n",
    "    (\"British\", \"JJ\", \"B-NORP\"),\n",
    "    (\"troops\", \"NNS\", \"O\"),\n",
    "    (\"from\", \"IN\", \"O\"),\n",
    "    (\"that\", \"DT\", \"O\"),\n",
    "    (\"country\", \"NN\", \"O\"),\n",
    "    (\".\", \".\", \"O\"),\n",
    "]\n",
    "\n",
    "sol3_b1 = {\n",
    "    \"bias\": 1.0,\n",
    "    \"token.lower()\": \"through\",\n",
    "    \"token[-3:]\": \"ugh\",\n",
    "    \"token[-2:]\": \"gh\",\n",
    "    \"token.isupper()\": False,\n",
    "    \"token.istitle()\": False,\n",
    "    \"token.isdigit()\": False,\n",
    "    \"postag\": \"IN\",\n",
    "    \"postag[:2]\": \"IN\",\n",
    "    \"-1:token.lower()\": \"marched\",\n",
    "    \"-1:token.istitle()\": False,\n",
    "    \"-1:token.isupper()\": False,\n",
    "    \"-1:postag\": \"VBN\",\n",
    "    \"+1:token.lower()\": \"london\",\n",
    "    \"+1:token.istitle()\": True,\n",
    "    \"+1:token.isupper()\": False,\n",
    "    \"+1:postag\": \"NNP\",\n",
    "}\n",
    "\n",
    "assert sent2features(ex3_b1)[5] == sol3_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a3e886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in processed]\n",
    "y = [sent2labels(s) for s in processed]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d0682",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c876edf1ff1c884b68896d397696429a",
     "grade": false,
     "grade_id": "cell-6f8321146de778a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If the training lasts longer than ~10 minutes, you can reduce `max_iterations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cddbc09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm=\"lbfgs\", c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6075ca4c",
   "metadata": {},
   "source": [
    "CRF should heavily outperform our previous attempt with the classifier. Check the performance without the `O` tag. If you wish, you can see how $F_1$ changes if you include the `O` tag, simply by setting `labels=classes` in `flat_classification_report`. The benefits of solving NER as a sequence labeling task should be obvious after you inspect the margin of improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a074f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass labels=['B-ART', 'B-EVE', 'B-GEO', 'B-GPE', 'B-NAT', 'B-ORG', 'B-PER', 'B-TIM', 'I-ART', 'I-EVE', 'I-GEO', 'I-GPE', 'I-NAT', 'I-ORG', 'I-PER', 'I-TIM'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "C:\\Users\\Ivan\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ART       0.00      0.00      0.00         0\n",
      "       B-EVE       0.00      0.00      0.00         0\n",
      "       B-GEO       0.00      0.00      0.00         0\n",
      "       B-GPE       0.88      0.94      0.91      1749\n",
      "       B-NAT       0.00      0.00      0.00         0\n",
      "       B-ORG       0.76      0.70      0.72       740\n",
      "       B-PER       0.00      0.00      0.00         0\n",
      "       B-TIM       0.00      0.00      0.00         0\n",
      "       I-ART       0.00      0.00      0.00         0\n",
      "       I-EVE       0.00      0.00      0.00         0\n",
      "       I-GEO       0.00      0.00      0.00         0\n",
      "       I-GPE       0.86      0.87      0.86       370\n",
      "       I-NAT       0.00      0.00      0.00         0\n",
      "       I-ORG       0.76      0.82      0.79       878\n",
      "       I-PER       0.00      0.00      0.00         0\n",
      "       I-TIM       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.83      0.86      0.84      3737\n",
      "   macro avg       0.20      0.21      0.21      3737\n",
      "weighted avg       0.83      0.86      0.84      3737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_classes = [s.upper() for s in new_classes]\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49baecdf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28e4d706e8b2e88cc70ad6eb97ed47cb",
     "grade": false,
     "grade_id": "cell-101a4c137df7738a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's explore the top (un)likely transitions. Can you spot any expected patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc924d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "I-FAC          -> I-FAC         : 6.83986\n",
      "I-CARDINAL     -> I-CARDINAL    : 6.62248\n",
      "I-EVENT        -> I-EVENT       : 6.57318\n",
      "B-PERSON       -> I-PERSON      : 6.32764\n",
      "B-TIME         -> I-TIME        : 6.06083\n",
      "I-GPE          -> I-GPE         : 6.05518\n",
      "I-ORG          -> I-ORG         : 6.02829\n",
      "B-PERCENT      -> I-PERCENT     : 5.97228\n",
      "B-CARDINAL     -> I-CARDINAL    : 5.93175\n",
      "B-LOC          -> I-LOC         : 5.89972\n",
      "B-EVENT        -> I-EVENT       : 5.83768\n",
      "I-PERSON       -> I-PERSON      : 5.82728\n",
      "I-MONEY        -> I-MONEY       : 5.74150\n",
      "B-QUANTITY     -> I-QUANTITY    : 5.57306\n",
      "B-MONEY        -> I-MONEY       : 5.56706\n",
      "I-DATE         -> I-DATE        : 5.51564\n",
      "B-FAC          -> I-FAC         : 5.50932\n",
      "B-WORK_OF_ART  -> I-WORK_OF_ART : 5.47687\n",
      "B-DATE         -> I-DATE        : 5.40929\n",
      "I-TIME         -> I-TIME        : 5.40436\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-GPE          -> I-ORG         : -1.91419\n",
      "B-NORP         -> B-ORG         : -1.95154\n",
      "O              -> I-PERSON      : -2.00892\n",
      "O              -> I-TIME        : -2.03544\n",
      "O              -> I-QUANTITY    : -2.05200\n",
      "B-NORP         -> I-ORG         : -2.06648\n",
      "O              -> I-NORP        : -2.10472\n",
      "O              -> I-WORK_OF_ART : -2.10614\n",
      "B-PERSON       -> B-PERSON      : -2.22155\n",
      "O              -> I-LAW         : -2.25461\n",
      "O              -> I-FAC         : -2.36931\n",
      "I-ORG          -> B-PERSON      : -2.39807\n",
      "B-CARDINAL     -> I-DATE        : -2.45201\n",
      "O              -> I-MONEY       : -2.74646\n",
      "O              -> I-EVENT       : -2.89625\n",
      "O              -> I-CARDINAL    : -3.26777\n",
      "O              -> I-LOC         : -3.49675\n",
      "O              -> I-GPE         : -4.22621\n",
      "O              -> I-DATE        : -4.52183\n",
      "O              -> I-ORG         : -5.02950\n"
     ]
    }
   ],
   "source": [
    "top_n_trans = 20\n",
    "\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-14s -> %-14s: %0.5f\" % (label_from, label_to, weight))\n",
    "\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(top_n_trans))\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-top_n_trans:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362aae9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "678006c1883cea5032550f0a4f5b2c26",
     "grade": false,
     "grade_id": "cell-fd1243cfc20e9ac9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Additionally, let's take a look at the most important features for specific tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90ce0edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "5.61942 B-PERSON       -1:token.lower():mr.\n",
      "4.99355 O              bias\n",
      "4.96132 B-DATE         token[-3:]:day\n",
      "4.45379 B-LOC          token.lower():asia\n",
      "4.37708 B-CARDINAL     token.lower():millions\n",
      "4.36302 O              BOS\n",
      "4.22766 B-ORDINAL      token[-2:]:th\n",
      "4.21113 I-DATE         token[-2:]:0s\n",
      "4.19905 B-NORP         token.istitle()\n",
      "4.09768 O              token.lower():president\n",
      "3.73460 B-NORP         token.lower():shi'ite\n",
      "3.68081 B-ORG          token.lower():taliban\n",
      "3.67184 B-GPE          token.lower():ukrainian\n",
      "3.56562 O              token.lower():minister\n",
      "3.49082 B-ORG          token.lower():cholera\n",
      "3.46878 B-LOC          token.lower():siberia\n",
      "3.43886 B-PERSON       -1:token.lower():minister\n",
      "3.43404 O              +1:token.lower():pacific\n",
      "3.42720 B-NORP         token.lower():baluchistan\n",
      "3.41009 B-CARDINAL     token.lower():dozens\n",
      "3.39178 O              -1:token.lower():late\n",
      "3.38578 B-ORG          token.lower():commonwealth\n",
      "3.34223 I-DATE         -1:token.lower():last\n",
      "3.29128 O              token.lower():secretary\n",
      "3.25112 B-ORG          token[-3:]:era\n",
      "3.22208 B-PERSON       -1:token.lower():president\n",
      "3.19761 B-ORDINAL      token.lower():first\n",
      "3.14810 B-NORP         token.lower():tajikistan\n",
      "3.12876 B-ORG          token.lower():hezbollah\n",
      "3.11396 B-GPE          token.lower():washington\n",
      "\n",
      "Top negative:\n",
      "-1.96520 I-DATE         +1:token.lower():-\n",
      "-1.99379 B-GPE          -1:token.lower():-\n",
      "-1.99489 B-DATE         -1:postag:JJ\n",
      "-1.99859 O              token.lower():summer\n",
      "-2.00698 O              token.lower():percent\n",
      "-2.04087 B-NORP         token.lower():ukrainian\n",
      "-2.07049 O              token.lower():minutes\n",
      "-2.07514 B-GPE          token[-2:]:er\n",
      "-2.08984 O              token[-3:]:nth\n",
      "-2.15724 O              token.lower():morning\n",
      "-2.16250 O              token.lower():shi'ite\n",
      "-2.18521 O              token[-3:]:oon\n",
      "-2.23429 O              token.lower():years\n",
      "-2.27437 O              token.lower():decades\n",
      "-2.33176 O              token.lower():about\n",
      "-2.42756 O              token.lower():first\n",
      "-2.42827 O              token.lower():communist\n",
      "-2.54121 O              token.lower():thousands\n",
      "-2.55099 B-DATE         -1:token.lower():to\n",
      "-2.55312 O              postag:NNP\n",
      "-2.61067 O              token[-2:]:th\n",
      "-2.65785 O              token[-3:]:ual\n",
      "-2.72751 O              -1:token.lower():within\n",
      "-2.78994 O              postag:NNPS\n",
      "-2.94027 O              token.istitle()\n",
      "-3.10483 O              token.lower():daily\n",
      "-3.12814 O              postag:CD\n",
      "-3.12814 O              postag[:2]:CD\n",
      "-3.24232 O              token.lower():year\n",
      "-3.94437 B-NORP         -1:token.lower():-\n"
     ]
    }
   ],
   "source": [
    "top_n_feat = 30\n",
    "\n",
    "\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.5f %-14s %s\" % (weight, label, attr))\n",
    "\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(top_n_feat))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Top negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-top_n_feat:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee17db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e42321e71f2eafb801fc75c13a868d37",
     "grade": false,
     "grade_id": "cell-339eac0c87542c35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's conclude this assignment with an overview of CRF feature importance using the `eli5` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04d1df61",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'jinja2.ext' has no attribute 'with_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\n\u001b[0;32m      3\u001b[0m eli5\u001b[38;5;241m.\u001b[39mshow_weights(crf, top\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\eli5\\__init__.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[0;32m      4\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.11.0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformatters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     format_as_html,\n\u001b[0;32m      8\u001b[0m     format_html_styles,\n\u001b[0;32m      9\u001b[0m     format_as_text,\n\u001b[0;32m     10\u001b[0m     format_as_dict,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain_weights, explain_prediction\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain_weights_sklearn, explain_prediction_sklearn\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\eli5\\formatters\\__init__.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mFunctions to convert explanations to human-digestible formats.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mTODO: IPython integration, customizability.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m format_as_text\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhtml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m format_as_html, format_html_styles\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mas_dataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m         explain_weights_df, explain_weights_dfs,\n\u001b[0;32m     13\u001b[0m         explain_prediction_df, explain_prediction_dfs,\n\u001b[0;32m     14\u001b[0m         format_as_dataframe, format_as_dataframes,\n\u001b[0;32m     15\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\eli5\\formatters\\html.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrees\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree2text\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare_weighted_spans, PreparedWeightedSpans\n\u001b[1;32m---> 22\u001b[0m template_env \u001b[38;5;241m=\u001b[39m \u001b[43mEnvironment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPackageLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meli5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemplates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjinja2.ext.with_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m template_env\u001b[38;5;241m.\u001b[39mglobals\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mzip\u001b[39m, numpy\u001b[38;5;241m=\u001b[39mnp))\n\u001b[0;32m     26\u001b[0m template_env\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m     27\u001b[0m     weight_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m w, w_range: format_hsl(weight_color_hsl(w, w_range)),\n\u001b[0;32m     28\u001b[0m     remaining_weight_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m ws, w_range, pos_neg:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     format_decision_tree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m tree: _format_decision_tree(tree),\n\u001b[0;32m     34\u001b[0m ))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\jinja2\\environment.py:363\u001b[0m, in \u001b[0;36mEnvironment.__init__\u001b[1;34m(self, block_start_string, block_end_string, variable_start_string, variable_end_string, comment_start_string, comment_end_string, line_statement_prefix, line_comment_prefix, trim_blocks, lstrip_blocks, newline_sequence, keep_trailing_newline, extensions, optimized, undefined, finalize, autoescape, loader, cache_size, auto_reload, bytecode_cache, enable_async)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicies \u001b[38;5;241m=\u001b[39m DEFAULT_POLICIES\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# load extensions\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextensions \u001b[38;5;241m=\u001b[39m \u001b[43mload_extensions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_async \u001b[38;5;241m=\u001b[39m enable_async\n\u001b[0;32m    366\u001b[0m _environment_config_check(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\jinja2\\environment.py:117\u001b[0m, in \u001b[0;36mload_extensions\u001b[1;34m(environment, extensions)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m extension \u001b[38;5;129;01min\u001b[39;00m extensions:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(extension, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 117\u001b[0m         extension \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mcast(t\u001b[38;5;241m.\u001b[39mType[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtension\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mimport_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    119\u001b[0m     result[extension\u001b[38;5;241m.\u001b[39midentifier] \u001b[38;5;241m=\u001b[39m extension(environment)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\jinja2\\utils.py:149\u001b[0m, in \u001b[0;36mimport_string\u001b[1;34m(import_name, silent)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28m__import__\u001b[39m(import_name)\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'jinja2.ext' has no attribute 'with_'"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.show_weights(crf, top=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
